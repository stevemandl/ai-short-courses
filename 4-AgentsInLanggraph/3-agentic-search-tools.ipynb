{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d139f430-6ec6-4dab-8140-b13d4673b702",
   "metadata": {},
   "source": [
    "# Lesson 3: Agentic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b5a823-7312-478d-b952-05a220ce46a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "import os\n",
    "import boto3\n",
    "from tavily import TavilyClient\n",
    "\n",
    "model = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    model_kwargs=dict(temperature=0)\n",
    ")\n",
    "\n",
    "secrets_client = boto3.client('secretsmanager')\n",
    "os.environ['TAVILY_API_KEY'] = secrets_client.get_secret_value(\n",
    "    SecretId='TAVILY_API_KEY')[\"SecretString\"]\n",
    "client = TavilyClient(api_key=os.environ.get(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a6493-1f0f-4fac-9fd8-07d18d09f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run search\n",
    "result = client.search(\"What is in Nvidia's new Blackwell GPU?\",\n",
    "                       include_answer=True)\n",
    "\n",
    "# print the answer\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8757f-8b1e-40c9-a3a9-c5053f864f22",
   "metadata": {},
   "source": [
    "## Regular search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30656abf-99a9-4046-a6db-71119ecef800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose location (try to change to your own city!)\n",
    "\n",
    "city = \"San Francisco\"\n",
    "\n",
    "query = f\"\"\"\n",
    "    what is the current weather in {city}?\n",
    "    Should I travel there today?\n",
    "    \"weather.com\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475e67a-3cde-485f-8317-15f54e419f68",
   "metadata": {},
   "source": [
    "> Note: search was modified to return expected results in the event of an exception. High volumes of student traffic sometimes cause rate limit exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352fdd5e-5df7-40d4-9e6a-ad1859cfb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckduckgo_search\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from duckduckgo_search import DDGS\n",
    "import re\n",
    "\n",
    "ddg = DDGS()\n",
    "\n",
    "def search(query, max_results=6):\n",
    "    try:\n",
    "        results = ddg.text(query, max_results=max_results)\n",
    "        return [i[\"href\"] for i in results]\n",
    "    except Exception as e:\n",
    "        print(f\"returning previous results due to exception reaching ddg.\")\n",
    "        results = [ # cover case where DDG rate limits due to high deeplearning.ai volume\n",
    "            \"https://weather.com/weather/today/l/USCA0987:1:US\",\n",
    "            \"https://weather.com/weather/hourbyhour/l/54f9d8baac32496f6b5497b4bf7a277c3e2e6cc5625de69680e6169e7e38e9a8\",\n",
    "        ]\n",
    "        return results  \n",
    "\n",
    "\n",
    "for i in search(query):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc958f-3699-412a-9cc5-a0245f90ea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_weather_info(url):\n",
    "    \"\"\"Scrape content from the given URL\"\"\"\n",
    "    if not url:\n",
    "        return \"Weather information could not be found.\"\n",
    "    \n",
    "    # fetch data\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        return \"Failed to retrieve the webpage.\"\n",
    "\n",
    "    # parse result\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53a5a2-f1e5-4f9f-beba-6733d9e1fdfe",
   "metadata": {},
   "source": [
    "> Note: This produces a long output, you may want to right click and clear the cell output after you look at it briefly to avoid scrolling past it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da91ac7-aa7a-42f4-a9c4-c3a76c241409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use DuckDuckGo to find websites and take the first result\n",
    "url = search(query)[0]\n",
    "\n",
    "# scrape first wesbsite\n",
    "soup = scrape_weather_info(url)\n",
    "\n",
    "print(f\"Website: {url}\\n\\n\")\n",
    "print(str(soup.body)[:50000]) # limit long outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865b2818-99de-488d-a6e7-edf00b64b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text\n",
    "weather_data = []\n",
    "for tag in soup.find_all(['h1', 'h2', 'h3', 'p']):\n",
    "    text = tag.get_text(\" \", strip=True)\n",
    "    weather_data.append(text)\n",
    "\n",
    "# combine all elements into a single string\n",
    "weather_data = \"\\n\".join(weather_data)\n",
    "\n",
    "# remove all spaces from the combined text\n",
    "weather_data = re.sub(r'\\s+', ' ', weather_data)\n",
    "    \n",
    "print(f\"Website: {url}\\n\\n\")\n",
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e78401c-55de-4083-8c0f-4430ecdcac87",
   "metadata": {},
   "source": [
    "## Agentic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914e420-a13e-41f5-a2ef-81cf31dee203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run search\n",
    "result = client.search(query, max_results=1)\n",
    "\n",
    "# print first result\n",
    "data = result[\"results\"][0][\"content\"]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f1da4-2159-437b-be25-11f971042358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pygments import highlight, lexers, formatters\n",
    "\n",
    "# parse JSON\n",
    "parsed_json = json.loads(data.replace(\"'\", '\"'))\n",
    "\n",
    "# pretty print JSON with syntax highlighting\n",
    "formatted_json = json.dumps(parsed_json, indent=4)\n",
    "colorful_json = highlight(formatted_json,\n",
    "                          lexers.JsonLexer(),\n",
    "                          formatters.TerminalFormatter())\n",
    "\n",
    "print(colorful_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c3fa8-8aa1-41f6-b2aa-af1cf61e4728",
   "metadata": {},
   "source": [
    "<img src=\"./google_sample.png\" width=\"800\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd159c-1355-4199-aa43-d20449cc13a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19004c-e8ff-4d94-b538-a6415527f99a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
