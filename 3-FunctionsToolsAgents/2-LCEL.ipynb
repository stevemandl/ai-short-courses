{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5fa73a-eedd-4652-8bb6-a0d2e6bd2b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install docarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88e54e8-3e57-4b07-96a9-2056f0ee9333",
   "metadata": {},
   "source": [
    "# LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b3dcf-0e71-4477-9706-e81d092b5181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    model_kwargs=dict(temperature=0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619e240-008a-43b5-b024-434d87b2a98c",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b43274b-7a47-4d0e-807c-c1a5f386cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me a short joke about {topic}\"\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbdf57-e1f5-429e-8d18-3a066eb5b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12981124-997a-45c4-9498-f7efa20b7141",
   "metadata": {},
   "source": [
    "## More complex chain\n",
    "\n",
    "And Runnable Map to supply user-provided inputs to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a244009a-bd55-45b4-989c-b083cb57648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain_aws.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e47788-de7c-4759-9f0c-ee895b306732",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    [\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\")\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b0ae08-3119-434f-9c40-ebbb8f2be3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada8062-3005-401b-b4d3-8b5a18911799",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke(\"what do bears like to eat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb1f20-cf9a-4f47-8714-940cb3445e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142db042-e290-42fe-a958-c3bfed586e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae457ec2-04fe-4b48-85b7-168b1dc8d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableMap({\n",
    "    \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "}) | prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82383284-bae6-4ea7-9612-d714b49934b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50295861-a624-4eb9-9350-29beaa4cec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = RunnableMap({\n",
    "    \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54554e-35d5-46bd-bb8c-1c90b28be817",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c31f8f-b05b-4711-8827-2405caebfd11",
   "metadata": {},
   "source": [
    "## Bind\n",
    "\n",
    "and OpenAI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc104a77-43c5-4115-b8c0-569a7ad6c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1602f74b-385b-4318-86ab-e10665e5638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    model_kwargs=dict(temperature=0)\n",
    ").bind(tools=functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c350199-bf40-4a83-a276-ab7f5c646b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f7aad-d811-4605-add8-c5371390f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable.invoke({\"input\": \"what is the weather in sf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6932330-05a8-488b-93d2-673ccb82edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    },\n",
    "        {\n",
    "      \"name\": \"sports_search\",\n",
    "      \"description\": \"Search for news of recent sport events\",\n",
    "      \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"team_name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The sports team to search for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"team_name\"]\n",
    "      }\n",
    "    }\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec45a3e3-d89e-4c52-b8b7-306efddc5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = llm.bind(tools=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971ed78-681c-4846-9cdd-c58b1f2ae1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56112e64-8ec3-4d3e-b281-f95cb12a750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666389f5-c48a-4847-ba22-69509d0333f4",
   "metadata": {},
   "source": [
    "## Fallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aae542-b1ec-49e8-93fa-de3b0d007260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockLLM\n",
    "import json\n",
    "\n",
    "model_kwargs_llama = {\"temperature\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1819cb-f1b4-4f9d-8fe2-138fcefad2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = BedrockLLM(\n",
    "    model_id=\"meta.llama3-8b-instruct-v1:0\",\n",
    "    model_kwargs=model_kwargs_llama\n",
    ")\n",
    "simple_chain = simple_model | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62ffd49-b85b-423c-8395-56b17b4e6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge = \"write three poems. output in json format with keys: 'title', 'author', and 'first_line'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc677bd-9424-46d5-8418-6159674095fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d49075-2f58-4008-a22e-aa88af89bb2a",
   "metadata": {},
   "source": [
    "**Note**: The next line is expected to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cabd08-6eb3-44ad-98c2-9d7abee6f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68583f-7d18-4382-9f4d-46b120cc4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_model = ChatBedrock(\n",
    "    model_id=\"mistral.mistral-7b-instruct-v0:2\",\n",
    "    model_kwargs=dict(temperature=0)\n",
    ")\n",
    "chain = better_model | StrOutputParser() | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07367c44-c023-405e-ba33-9bedffe3b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b283fe1-2d0b-4e4c-9bfb-6537c61c6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = simple_chain.with_fallbacks([chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3db735-7de7-4054-bfdd-90e731270243",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600519fd-e7e9-43f5-9848-48399693de25",
   "metadata": {},
   "source": [
    "## Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd095f73-cd82-4158-8ae7-fbdad86afb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a short joke about {topic}\"\n",
    ")\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    model_kwargs=dict(temperature=0)\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286b482-f42b-441a-b5e6-284c9c170398",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"topic\": \"bears\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0155b4-1b01-426d-96f5-490deeb692d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.batch([{\"topic\": \"bears\"}, {\"topic\": \"frogs\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab27f0e2-4081-4d26-ad10-1a64ed8e1278",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in chain.stream({\"topic\": \"bears\"}):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d75485-648c-4512-8d59-626a90f77cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await chain.ainvoke({\"topic\": \"bears\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c95c2-22e1-4efc-81f4-57354fc34950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09635fc-cb3e-497a-85ba-fe6565e2808f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
